# Оптимизация процесса создания отчета

## Проблема
В проекте существует задача по формированию отчетов из файлов в формате .txt определенного формата

Отчеты должны создержать информацию об общем количестве пользователей,количестве сессий, 
количестве уникальных браузеров, а также персональную статистику по каждому пользователю

Написанная программа хорошо работает на небольших объемах входных данных, однако слишком медленно
работает на большом объеме входных данных.

Проблема возникла при попытке обработать файл объемом ~ 130 МБ
В результате возникшей проблемы было решено оптимизировать процесс создания данного отчета

## Формирование метрики
В качестве метрики было решено использовать время создания результирующего отчета (result.json)
в секундах
В качестве входных данных используется файл data_large.txt, размером ~ 130 МБ.
Бюджет был определен заказчиком и составляет 30 секунд

## Гарантия работы оптимизированной программы
В программе уже есть тест, выполнение которого теста в фидбек-лупе, созданном для тестирования,
позволяет не допустить изменения логики программы при оптимизации. В случае необходимости с 
помощью библиотеки RSpec будут написаны дополнительные тесты

## Формирование ассимптомтики
Для формирования ассимптотики была использована библиотека ruby_prof, для формирования flat отчета
Был сформирован файл data_test.txt, в который постпепенно добавлялись данные для исследования
эффективности алгоритма
В результате были получены следующие тестовые данные
1 200 пользователей ~ 2.2 секунды
2 400 пользователей ~ 9.6 секунд
3 800 пользователей ~ 39 секунд

Исходя из полученных данных был сделан вывод, что алгоритм менее эффективен, чем линейный.
Также предварительно было выявлено, что большую часть процессорного времени занимают такие
методы, как `<Class::Date>#parse`, `Array#map` и `Regexp#match`

## Feedback-Loop

